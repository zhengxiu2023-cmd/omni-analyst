# -*- coding: utf-8 -*-
import logging
from typing import List, Dict

from core.models import NewsItem
from core.network_engine import safe_request

logger = logging.getLogger(__name__)

# æ”¯æŒçš„å¹³å°åŠæƒé‡
PLATFORMS = {
    'weibo': {'name': 'å¾®åšçƒ­æœ', 'weight': 10},
    'douyin': {'name': 'æŠ–éŸ³çƒ­æ¦œ', 'weight': 9},
    'zhihu': {'name': 'çŸ¥ä¹çƒ­æ¦œ', 'weight': 7},
    'xueqiu': {'name': 'é›ªçƒ', 'weight': 8},
}

KEYWORDS = [
    'è‚¡', 'è‚¡å¸‚', 'è‚¡ç¥¨', 'Aè‚¡', 'æ¸¯è‚¡', 'ç¾è‚¡', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿', 
    'æ¶¨åœ', 'è·Œåœ', 'å¤§æ¶¨', 'æš´æ¶¨', 'é£™å‡', 'æš´è·Œ', 'æ¶¨å¹…', 'è·Œå¹…', 'ç¿»å€',
    'æ¦‚å¿µ', 'é¾™å¤´', 'é¢˜æ', 'ç™½é©¬', 'è“ç­¹', 'ä¸Šå¸‚', 'IPO', 'é‡ç»„',
    'ç‰›å¸‚', 'ç†Šå¸‚', 'åå¼¹', 'å›è°ƒ', 'éœ‡è¡', 'çªç ´', 'æ–°é«˜', 'ä¸»åŠ›', 'æ¸¸èµ„',
    'åŒ—å‘', 'å¤–èµ„', 'æœºæ„', 'èµ„é‡‘', 'æ¿å—', 'èµ›é“', 'è½®åŠ¨', 'çƒ­ç‚¹',
    'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'æ–°èƒ½æº', 'äººå·¥æ™ºèƒ½', 'å¤§æ¨¡å‹'
]

def fetch_social_hot_topics() -> List[NewsItem]:
    """
    é€šè¿‡å¤–éƒ¨APIè·å–å››å¤§ç¤¾äº¤å¹³å°çš„æµé‡çƒ­æ¦œï¼Œå¹¶æå–è‚¡ç¥¨ç›¸å…³çš„è¯æ¡ï¼Œè®¡ç®—ç®€å•çš„æµé‡çƒ­åº¦å¾—åˆ†ã€‚
    """
    base_url = "https://newsapi.ws4.cn/api/v1/dailynews/"
    results: List[NewsItem] = []
    
    for platform, info in PLATFORMS.items():
        try:
            resp = safe_request(base_url, method="get", params={"platform": platform})
            if resp is None:
                continue
                
            data = resp.json()
            if data.get('status') != '200':
                logger.warning("[ç¤¾äº¤æµé‡] %s APIè¿”å›çŠ¶æ€å¼‚å¸¸", info['name'])
                continue
                
            news_list = data.get('data', [])
            platform_name = info['name']
            weight = info['weight']
            
            for index, item in enumerate(news_list):
                rank = index + 1
                title = item.get('title', '')
                content = item.get('content', '')
                text = f"{title} {content}"
                
                matched_keywords = [kw for kw in KEYWORDS if kw in text]
                if matched_keywords:
                    # ç®€åŒ–ç‰ˆæµé‡çƒ­åº¦å¾—åˆ† = æ’åçš„å€’æ•°åˆ†å€¼ + å¹³å°æƒé‡ + å…³é”®è¯ä¸ªæ•°æƒé‡
                    rank_score = max(0, 100 - rank * 2)
                    keyword_score = len(matched_keywords) * 5
                    total_score = rank_score + (weight * 10) + keyword_score
                    
                    results.append(NewsItem(
                        time=item.get('publish_time', 'å½“å‰ç¤¾äº¤çƒ­æ¦œ'),
                        title=f"æµé‡çˆ†å‘ï¼ã€{platform_name}ã€‘{title} (çƒ­åº¦å¾—åˆ†: {total_score})",
                        source=platform_name,
                        tags=[f"ğŸ”¥ [ç¤¾äº¤æµé‡å…±æŒ¯]"],
                        score=1 if total_score > 120 else 0,
                        llm_reasoning=f"å‘½ä¸­è‚¡å¸‚é«˜çƒ­å…³é”®è¯ {matched_keywords}ï¼Œå…¨ç½‘æµé‡æ±‡èšã€‚"
                    ))
                    
        except Exception as e:
            logger.warning("[ç¤¾äº¤æµé‡] è·å– %s å¹³å°çƒ­æ¦œå¤±è´¥: %s", info['name'], e)
            
    # æŒ‰æµé‡çƒ­åº¦æ’åºï¼Œä¿ç•™å‰ 15 æ¡
    results.sort(key=lambda x: int(x.title.split("çƒ­åº¦å¾—åˆ†: ")[1].split(")")[0]) if "çƒ­åº¦å¾—åˆ†:" in x.title else 0, reverse=True)
    logger.info("[ç¤¾äº¤æµé‡] è·å–å…¨ç½‘çƒ­æœå®Œæ¯•ï¼Œæå–è‚¡å¸‚ç›¸å…³æƒ…æŠ¥: %d æ¡ã€‚", len(results))
    return results[:15]
