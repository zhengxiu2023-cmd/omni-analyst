# -*- coding: utf-8 -*-
"""
ğŸŒŠ fetchers/news_flow_fetcher.py â€” è¶…æ™¯æ°”åº•æ–™é›·è¾¾ (Hyper-Prosperity Radar)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
èŒè´£ï¼š
  - æ ¸å¿ƒä½¿å‘½æ˜¯å¯¹æŠ—å™ªéŸ³ï¼Œèšåˆå¤§ä¼—è½¨(å¾®åš/æŠ–éŸ³)ä¸é€»è¾‘è½¨(çŸ¥ä¹/é›ªçƒ)çš„çƒ­æœã€‚
  - å¼•å…¥æœ¬åœ°ç¥ç»æçº¯å¼•æ“ (LLM) è¿›è¡Œä¸‰ç»´æ¡†æ¶åˆ¤åˆ« ([ç§‘æŠ€çªå˜]/[æ”¿ç»å¤§å±€]/[ä¾›éœ€æå€¼])ã€‚
  - é€šè¿‡ä»£ç åæŸ¥è·¨æœæ¦œå•ï¼Œç¡®è®¤ [çœŸÂ·ç°è±¡çº§ç ´åœˆ] æŠ‘æˆ– [é€»è¾‘å­•è‚²æœŸ]ã€‚
  - æ•°æ®ä¸å…¥åº“ï¼Œç›´æ¥ç”Ÿæˆææ˜“åå’½çš„ Markdown å–‚å…¥ç›®æ ‡å…¬å¸çš„ 00_å‚æ•°é¢æ¿ã€‚
"""

import logging
import json
import os
import requests
from typing import List, Dict, Any
from datetime import datetime

from core.models import HyperProsperityEvent
from core.network_engine import safe_request
from config import API_CONFIG, LLM_CONFIG, EXPORT_CONFIG

logger = logging.getLogger(__name__)

MASS_TRACK = ["weibo", "douyin", "kuaishou"]
LOGIC_TRACK = ["zhihu", "xueqiu", "cls", "toutiao"]

# Kå€¼ç¼“å­˜ {platform: {title: last_rank_score}}
_hot_cache: Dict[str, Dict[str, float]] = {}

def _fetch_platform_hot(platform: str, limit: int = 50) -> List[Dict]:
    """è·å–æŒ‡å®šå¹³å°çš„ Top 50 çƒ­æ¦œ"""
    url = f"https://newsapi.ws4.cn/api/v1/dailynews/?platform={platform}"
    results = []
    try:
        resp = safe_request(url, method="get", headers=API_CONFIG["HEADERS"], stream=False)
        if resp and resp.status_code == 200:
            data = resp.json()
            if data.get("code") == 200 and data.get("data"):
                for idx, item in enumerate(data["data"][:limit]):
                    title = str(item.get("title", "")).strip()
                    desc = str(item.get("desc", "")).strip()
                    if title:
                        results.append({
                            "platform": platform,
                            "rank": idx + 1,
                            "title": title,
                            "desc": desc
                        })
    except Exception as exc:
        logger.warning(f"[çƒ­æ¦œé‡‡é›†] å¹³å° {platform} é‡‡é›†å¤±è´¥: {exc}")
    return results

def _calculate_base_score(rank: int, max_rank: int = 50) -> float:
    """çƒ­åº¦åˆ†ï¼šæ’åè¶Šé å‰åˆ†æ•°è¶Šé«˜"""
    if rank <= 0 or rank > max_rank:
        return 1.0
    return round(100.0 - (rank / max_rank) * 90.0, 2)

def _evaluate_with_local_llm(events: List[Dict]) -> List[Dict]:
    """
    é€šè¿‡æœ¬åœ° LLM å¯¹åˆæ­¥å‘½ä¸­çš„çƒ­æ¦œäº‹ä»¶è¿›è¡Œæçº¯ä¸æ¡†æ¶æ˜ å°„ã€‚
    ä¼ å…¥åŒ…å« title å’Œ desc çš„å­—å…¸åˆ—è¡¨ã€‚
    """
    if not events:
        return []
        
    prompt_text = "è¯·ä½œä¸ºè¶…æ™¯æ°”ä»·å€¼æŠ•æœºåˆ†æå¸ˆï¼Œè¯„ä¼°ä»¥ä¸‹æ–°é—»äº‹ä»¶ã€‚åˆ¤æ–­å®ƒä»¬æ˜¯å¦å±äº[ç§‘æŠ€çªå˜]ã€[æ”¿ç»å¤§å±€]æˆ–[ä¾›éœ€æå€¼]ã€‚è‹¥æ˜¯å™ªéŸ³æˆ–å…«å¦è¯·ä¸¢å¼ƒ(Discard)ã€‚\n\näº‹ä»¶åˆ—è¡¨ï¼š\n"
    for idx, e in enumerate(events):
        prompt_text += f"{idx+1}. æ ‡é¢˜ï¼š{e['title']} | æ‘˜è¦ï¼š{e['desc'][:100]}\n"
        
    prompt_text += """
è¯·ä¸¥æ ¼ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›è¢«é€‰ä¸­çš„äº‹ä»¶ï¼ˆä¸¢å¼ƒçš„ä¸è¿”å›ï¼‰ã€‚æ ¼å¼ï¼š
[
  {
    "original_title": "å®Œå…¨å¯¹åº”åŸæ–‡æ ‡é¢˜",
    "category": "[ç§‘æŠ€çªå˜/æ”¿ç»å¤§å±€/ä¾›éœ€æå€¼ ä¸‰é€‰ä¸€]",
    "summary": "1å¥è¯äº‹ä»¶æ ¸å¿ƒæ‘˜è¦",
    "key_signals": ["ä¿¡æ¯ç´ 1", "ä¿¡æ¯ç´ 2"]
  }
]
"""
    
    payload = {
        "model": LLM_CONFIG["MODEL_NAME"],
        "prompt": prompt_text,
        "stream": False,
        "format": "json"
    }
    
    try:
        resp = requests.post(LLM_CONFIG["OLLAMA_API"], json=payload, timeout=LLM_CONFIG.get("TIMEOUT", 60))
        resp.raise_for_status()
        res_json = resp.json().get("response", "[]")
        
        # ç®€å•æ¸…æ´—
        import re
        clean_text = res_json.strip()
        match = re.search(r"```(?:json)?\s*(.*?)\s*```", clean_text, re.DOTALL)
        if match:
            clean_text = match.group(1).strip()
            
        return json.loads(clean_text)
    except Exception as exc:
        logger.warning(f"[LLMå¼•æ“] æ‰¹é‡æçº¯äº‹ä»¶å¤±è´¥: {exc}")
        return []

def fetch_social_hot_topics(stock_name: str, stock_code: str, industry_keywords: List[str] = None, save_dir: str = None) -> List[HyperProsperityEvent]:
    """
    æ ¸å¿ƒæ‰§è¡Œå™¨ï¼šè·å–åŒè½¨çƒ­æ¦œ -> å…³é”®è¯åˆç­› -> LLM æ¼æ–—è¿‡æ»¤ -> è®¡ç®—å…±æŒ¯/Kå€¼ -> è¿½åŠ è‡³é¢æ¿
    """
    if not industry_keywords:
        industry_keywords = []
        
    hit_words = [stock_name, stock_code] + industry_keywords
    logger.info(f"[é›·è¾¾å¼•æ“] å¯åŠ¨å…¨ç½‘åŒè½¨æ‰«æï¼Œæœç´¢è¯å›Š: {hit_words}")
    
    # è·å–åŸå§‹æ¦œå•
    mass_items = []
    logic_items = []
    for p in MASS_TRACK:
        mass_items.extend(_fetch_platform_hot(p))
    for p in LOGIC_TRACK:
        logic_items.extend(_fetch_platform_hot(p))
        
    all_items = mass_items + logic_items
    
    # å…³é”®è¯åˆç­›ï¼ˆé™å™ªé˜² LLM è¿‡è½½ï¼‰
    candidate_items = []
    for item in all_items:
        if any(word in item['title'] or word in item['desc'] for word in hit_words):
            candidate_items.append(item)
            
    # å»é‡å¤„ç†ï¼ˆç›¸åŒæ ‡é¢˜å¯èƒ½åœ¨å¤šä¸ªå¹³å°ï¼‰
    unique_candidates = {item['title']: item for item in candidate_items}.values()
    
    if not unique_candidates:
        logger.info("[é›·è¾¾å¼•æ“] åˆç­›æ— ç›¸å…³äº‹ä»¶å‘½ä¸­ã€‚")
        return []
        
    logger.info(f"[é›·è¾¾å¼•æ“] åˆç­›å¾—åˆ° {len(unique_candidates)} æ¡æ½œåœ¨äº‹ä»¶ï¼ŒæŠ•å…¥ LLM æ´—ç­¹...")
    
    llm_results = _evaluate_with_local_llm(list(unique_candidates))
    
    final_events = []
    markdown_lines = []
    
    for l_res in llm_results:
        target_title = l_res.get("original_title", "")
        if not target_title:
            continue
            
        # åæŸ¥åŒè½¨å…±æŒ¯
        in_mass = [i for i in mass_items if target_title in i['title']]
        in_logic = [i for i in logic_items if target_title in i['title']]
        
        is_mass_hit = len(in_mass) > 0
        is_logic_hit = len(in_logic) > 0
        
        if is_mass_hit and is_logic_hit:
            resonance = "[çœŸÂ·ç°è±¡çº§ç ´åœˆ]"
            evidence = f"å¤§ä¼—è½¨(å¦‚ {in_mass[0]['platform']} Top{in_mass[0]['rank']}) ä¸ é€»è¾‘è½¨(å¦‚ {in_logic[0]['platform']} Top{in_logic[0]['rank']}) å¼ºçƒˆå…±æŒ¯"
        elif is_logic_hit:
            resonance = "[é€»è¾‘å­•è‚²æœŸ]"
            evidence = f"å±€é™äºé€»è¾‘è½¨(å¦‚ {in_logic[0]['platform']} Top{in_logic[0]['rank']}) å‘é…µï¼Œç­‰å¾…ç ´åœˆ"
        elif is_mass_hit:
            resonance = "[å¤§ä¼—æƒ…ç»ªç‹‚çƒ­]"
            evidence = f"ä»…å­˜åœ¨äºå¤§ä¼—è½¨(å¦‚ {in_mass[0]['platform']} Top{in_mass[0]['rank']})ï¼Œç¼ºä¹ä¸“ä¸šé€»è¾‘æ”¯æ’‘"
        else:
            continue # æœªèƒ½åŒ¹é…ä¸Š
            
        # è®¡ç®— K å€¼ï¼ˆå–ç»¼åˆçƒ­åº¦ï¼‰
        current_heat = sum(_calculate_base_score(i['rank']) for i in in_mass + in_logic)
        # ç”¨æ ‡é¢˜ä½œ cache key
        last_heat = _hot_cache.get("GLOBAL", {}).get(target_title, current_heat * 0.5)
        # å…œåº•é¿å… 0
        if last_heat <= 0:
            last_heat = 1.0
        k_value = round(current_heat / last_heat, 2)
        
        # æ›´æ–°ç¼“å­˜
        if "GLOBAL" not in _hot_cache:
            _hot_cache["GLOBAL"] = {}
        _hot_cache["GLOBAL"][target_title] = current_heat
        
        evt = HyperProsperityEvent(
            title=l_res.get("summary", target_title),
            category=l_res.get("category", "[æœªåˆ†ç±»]"),
            resonance=resonance,
            k_value=k_value,
            key_signals=l_res.get("key_signals", [])
        )
        final_events.append(evt)
        
        momentum_desc = f"Kå€¼ = {k_value} "
        if k_value > 1.5:
            momentum_desc += "[å¢é‡çˆ†å‘æœŸ]"
        elif k_value < 0.8:
            momentum_desc += "[è¡°é€€æœŸ]"
        else:
            momentum_desc += "[é«˜ä½éœ‡è¡æœŸ]"
            
        def _sa(v, default="[æ•°æ®æœªè·å–]"):
            return default if v is None or str(v).strip() in ("", "None", "nan") else str(v)
            
        sig_str = ", ".join([_sa(s) for s in evt.key_signals]) if evt.key_signals else "[æ•°æ®æœªè·å–]"
        
        md_block = f"""
### ğŸ“¡ è¶…æ™¯æ°”åº•å±‚æƒ…æŠ¥é›·è¾¾ (Hyper-Prosperity Radar)
- **æ ¸å¿ƒäº‹ä»¶**: {_sa(evt.title)}
- **æ¡†æ¶æ˜ å°„**: {_sa(evt.category)}
- **å…±æŒ¯éªŒè¯**: {_sa(evt.resonance)} ({_sa(evidence)})
- **æƒ…ç»ªåŠ¨é‡**: {_sa(momentum_desc)}
- **å…³é”®ä¿¡æ¯ç´ **: [{sig_str}]
"""     
        markdown_lines.append(md_block)
        logger.info(f"[é›·è¾¾å¼•æ“] æ•è·å¤§äº‹ä»¶: {_sa(evt.title)} ({_sa(evt.resonance)})")

    if markdown_lines and save_dir:
        panel_path = os.path.join(save_dir, EXPORT_CONFIG["PANEL_FILENAME"])
        try:
            with open(panel_path, "a", encoding="utf-8") as f:
                f.write("\n" + "".join(markdown_lines) + "\n")
            logger.info(f"[é›·è¾¾å¼•æ“] å·²è¿½åŠ  {len(markdown_lines)} æ¡ç¡¬æ ¸é›·è¾¾æ‘˜è¦è‡³é¢æ¿")
        except Exception as e:
            logger.error(f"[é›·è¾¾å¼•æ“] æ— æ³•å†™å…¥å‚æ•°é¢æ¿: {e}")
            
    return final_events

def execute_radar_scan(stock_code: str, stock_name: str) -> str:
    """
    ä¸“ä¸º V8.3 é›†æˆæä¾›çš„å…¥å£ï¼Œè¿”å›åˆå¹¶å¥½çš„è¶…æ™¯æ°”æµé‡æ‘˜è¦å­—ç¬¦ä¸² (Markdown)ï¼Œä¾›ä¸Šå±‚ç›´æ¥æ³¨å…¥å‚æ•°é¢æ¿ã€‚
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        stock_name: è‚¡ç¥¨åç§°
        
    Returns:
        Formatted markdown string combining all hyper-prosperity events found.
    """
    try:
        events = fetch_social_hot_topics(stock_name, stock_code, save_dir=None)
        if not events:
            return "æœªç›‘æµ‹åˆ°ç°è±¡çº§ç ´åœˆä¿¡å·æˆ–å¤§å±€å…±æŒ¯ï¼ˆå½“å‰çƒ­åº¦æœªèƒ½ç©¿é€ LLM æçº¯æ¼æ–—ï¼‰ã€‚"
            
        summary_lines = []
        for evt in events:
            k_val = f"K={evt.k_value}" if evt.k_value > 0 else ""
            signals_str = ", ".join(evt.key_signals) if evt.key_signals else "æ— "
            summary_lines.append(
                f"- **{evt.category}** {evt.resonance} {k_val}: {evt.title} "
                f"*(æå–ä¿¡æ¯ç´ : {signals_str})*"
            )
        return "\n".join(summary_lines)
    except Exception as exc:
        logger.error(f"[é›·è¾¾æ‰«æ] æ‰§è¡Œå¼‚å¸¸: {exc}")
        return f"[æµé‡é›·è¾¾æå–å¤±è´¥: {exc}]"
