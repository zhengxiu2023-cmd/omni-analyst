# -*- coding: utf-8 -*-
"""
ğŸ” fetchers/cninfo_spider.py â€” å·¨æ½®èµ„è®¯ç½‘è´¢æŠ¥çˆ¬è™«
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
èŒè´£ï¼š
  - ä»å·¨æ½®èµ„è®¯ç½‘ï¼ˆcninfo.com.cnï¼‰æ£€ç´¢å¹¶ä¸‹è½½ç›®æ ‡è‚¡/ç«å¯¹è‚¡çš„è´¢æŠ¥ PDFã€‚
  - ä½¿ç”¨ core.network_engine.stream_download è¿›è¡Œ Chunk æµå¼å†™å…¥ï¼Œé˜² OOMã€‚
  - ä½¿ç”¨ core.network_engine.safe_request å‘èµ· JSON æ£€ç´¢è¯·æ±‚ï¼Œäº«å—é˜²å¼¹é‡è¯•ã€‚
  - åŸºäº INVESTOR_DOC_KEYWORDS å¯¹è°ƒç ”çºªè¦è¿›è¡Œç²¾å‡†åè¿‡æ»¤ï¼Œä¿®å¤æ—§ä»£ç çš„æ¼æŠ“é—®é¢˜ã€‚
  - æ”¯æŒå¢é‡ä¸‹è½½ï¼šæ–‡ä»¶å·²å­˜åœ¨åˆ™è·³è¿‡ï¼Œé¿å…é‡å¤ä¸‹è½½ã€‚

é…ç½®æ¥æºï¼š
  config.py > API_CONFIG / CNINFO_CATEGORIES / INVESTOR_DOC_KEYWORDS
               RE_ILLEGAL_FILENAME_CHARS

æ•°æ®å¥‘çº¦å¯¹åº”ï¼š
  ä¸‹è½½å®Œæˆåè°ƒç”¨ utils/pdf_extractor æå–å¢é‡ RAG å†…å®¹ï¼Œè¿½åŠ å†™å…¥å‚æ•°é¢æ¿ã€‚
"""

import logging
import os
import re
import time
from pathlib import Path

from config import (
    API_CONFIG,
    CNINFO_CATEGORIES,
    EXPORT_CONFIG,
    INVESTOR_DOC_KEYWORDS,
    RE_ILLEGAL_FILENAME_CHARS,
)
from core.network_engine import safe_request, stream_download
from utils.pdf_extractor import extract_rag_info_from_pdf

logger = logging.getLogger(__name__)

# ä¸¤æ¬¡ PDF ä¸‹è½½ä¹‹é—´çš„ç¤¼è²Œå»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œé¿å…è§¦å‘å·¨æ½®åçˆ¬é™é€Ÿ
_DOWNLOAD_DELAY: float = 1.2

# å·¨æ½®æ·±å¸‚/æ²ªå¸‚åˆ—è¡¨æ¥å£ï¼ˆç”¨äºè·å– orgIdï¼‰
_CNINFO_STOCK_LIST_URLS: dict[str, str] = {
    "szse": API_CONFIG["CNINFO_STOCK_LIST_SZ"],
    "sse": API_CONFIG["CNINFO_STOCK_LIST_SH"],
}

# å†…å­˜ä¸­ç¼“å­˜è‚¡ç¥¨ orgId åˆ—è¡¨ï¼Œé¿å…é‡å¤æ‹‰å–ï¼ˆè¿›ç¨‹çº§ç¼“å­˜ï¼‰
_org_cache: dict[str, str] = {}


# ===========================================================================
# å…¬å…±æ¥å£
# ===========================================================================
def download_company_reports(
    code: str,
    name: str,
    save_dir: str,
    is_rival: bool = False,
) -> None:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘æ£€ç´¢å¹¶æµå¼ä¸‹è½½æŒ‡å®šè‚¡ç¥¨çš„è´¢æŠ¥ PDFã€‚

    ç›®æ ‡è‚¡ï¼ˆis_rival=Falseï¼‰ä¸‹è½½æ¸…å•ï¼š
      - å¹´åº¦æŠ¥å‘Šï¼ˆæœ€è¿‘ 2 ä»½ï¼‰
      - åŠå¹´åº¦æŠ¥å‘Šï¼ˆæœ€è¿‘ 2 ä»½ï¼‰
      - ä¸‰å­£åº¦æŠ¥å‘Šï¼ˆæœ€è¿‘ 2 ä»½ï¼‰
      - ä¸€å­£åº¦æŠ¥å‘Šï¼ˆæœ€è¿‘ 1 ä»½ï¼‰
      - æŠ•èµ„è€…è°ƒç ”çºªè¦ï¼ˆå…³é”®è¯æœç´¢ + INVESTOR_DOC_KEYWORDS ç²¾å‡†åè¿‡æ»¤ï¼Œæœ€å¤š 5 ä»½ï¼‰

    ç«å¯¹è‚¡ï¼ˆis_rival=Trueï¼‰ä¸‹è½½æ¸…å•ï¼š
      - å¹´åº¦æŠ¥å‘Šï¼ˆæœ€è¿‘ 1 ä»½ï¼‰
      - ä¸‰å­£åº¦æŠ¥å‘Šï¼ˆæœ€è¿‘ 1 ä»½ï¼‰

    Args:
        code:     6 ä½ A è‚¡ä»£ç ï¼ˆä¸å«å¸‚åœºå‰ç¼€ï¼‰ã€‚
        name:     è‚¡ç¥¨ä¸­æ–‡åç§°ï¼ˆç”¨äºæ—¥å¿—ä¸æ–‡ä»¶å¤¹å‘½åï¼‰ã€‚
        save_dir: æœ¬åœ°ä¿å­˜ç›®å½•ï¼ˆå¿…é¡»å·²å­˜åœ¨ï¼‰ã€‚
        is_rival: True è¡¨ç¤ºç«å¯¹è‚¡ï¼ˆä¸‹è½½èŒƒå›´ç¼©å‡ï¼‰ï¼ŒFalse è¡¨ç¤ºç›®æ ‡è‚¡ï¼ˆå…¨é‡ä¸‹è½½ï¼‰ã€‚
    """
    logger.info(
        "[å·¨æ½®] å¼€å§‹ä¸‹è½½ %s(%s) | æ¨¡å¼=%s",
        name, code, "ç«å¯¹" if is_rival else "ç›®æ ‡",
    )

    if is_rival:
        # ç«å¯¹è‚¡ï¼šä»…å¹´æŠ¥ + æœ€æ–°å­£æŠ¥
        _download_category(code, name, CNINFO_CATEGORIES["ANNUAL_REPORT"], 1, save_dir)
        _download_category(code, name, CNINFO_CATEGORIES["Q3_REPORT"], 1, save_dir)
    else:
        # ç›®æ ‡è‚¡ï¼šå…¨é‡åº•ç¨¿
        _download_category(code, name, CNINFO_CATEGORIES["ANNUAL_REPORT"], 2, save_dir)
        _download_category(code, name, CNINFO_CATEGORIES["SEMI_ANNUAL"], 2, save_dir)
        _download_category(code, name, CNINFO_CATEGORIES["Q3_REPORT"], 2, save_dir)
        _download_category(code, name, CNINFO_CATEGORIES["Q1_REPORT"], 1, save_dir)
        # æŠ•èµ„è€…è°ƒç ”çºªè¦ï¼šsearchkey å…¨æ–‡æœç´¢ + å…³é”®è¯ç²¾å‡†åè¿‡æ»¤
        _download_category(
            code, name, category="", limit=5, save_dir=save_dir,
            searchkey="è°ƒç ”", use_investor_filter=True,
        )

    logger.info("[å·¨æ½®] %s(%s) å…¨éƒ¨ä¸‹è½½ä»»åŠ¡å®Œæˆã€‚", name, code)


# ===========================================================================
# ç§æœ‰ï¼šè·å–è‚¡ç¥¨ orgIdï¼ˆå·¨æ½®æ¥å£çš„å¿…è¦å‚æ•°ï¼‰
# ===========================================================================
def _get_org_id(code: str) -> str:
    """
    ä»å·¨æ½®èµ„è®¯ç½‘è·å–è‚¡ç¥¨çš„ orgIdã€‚

    orgId æ˜¯å·¨æ½®å…¬å‘Šæ£€ç´¢æ¥å£çš„å¿…è¦å‚æ•°ï¼Œç”¨äºç²¾å‡†å®šä½å…¬å¸ã€‚
    æ·±å¸‚ï¼ˆé 6 å¼€å¤´ï¼‰æŸ¥ szse åˆ—è¡¨ï¼Œæ²ªå¸‚ï¼ˆ6 å¼€å¤´ï¼‰æŸ¥ sse åˆ—è¡¨ã€‚

    Args:
        code: 6 ä½ A è‚¡ä»£ç ã€‚

    Returns:
        orgId å­—ç¬¦ä¸²ï¼›è‹¥æŸ¥è¯¢å¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²ï¼ˆæ¥å£ä»å¯é™çº§ä½¿ç”¨ç©º orgIdï¼‰ã€‚
    """
    if code in _org_cache:
        return _org_cache[code]

    # æ ¹æ®è‚¡ç¥¨ä»£ç é€‰æ‹©æŸ¥è¯¢çš„äº¤æ˜“æ‰€åˆ—è¡¨
    exchange_key: str = "sse" if str(code).startswith("6") else "szse"
    list_url: str = _CNINFO_STOCK_LIST_URLS[exchange_key]

    try:
        resp = safe_request(list_url, method="get")
        if resp is None:
            return ""

        stock_list: list[dict] = resp.json().get("stockList", [])
        logger.debug("[å·¨æ½®] %s è‚¡ç¥¨åº“åŠ è½½: %d æ¡ã€‚", exchange_key.upper(), len(stock_list))

        # å»ºç«‹ code -> orgId çš„æ˜ å°„å¹¶ç¼“å­˜ï¼Œé¿å…é‡å¤è¯·æ±‚
        for stock in stock_list:
            stk_code: str = stock.get("code", "")
            org_id: str = stock.get("orgId", "")
            if stk_code:
                _org_cache[stk_code] = org_id

        return _org_cache.get(code, "")

    except Exception as exc:
        logger.error("[å·¨æ½®] orgId è·å–å¤±è´¥(%s): %s", code, exc)
        return ""


# ===========================================================================
# ç§æœ‰ï¼šæ‰§è¡Œå•ä¸€ç±»åˆ«çš„å…¬å‘Šæ£€ç´¢ä¸ä¸‹è½½
# ===========================================================================
def _download_category(
    code: str,
    name: str,
    category: str,
    limit: int,
    save_dir: str,
    searchkey: str = "",
    use_investor_filter: bool = False,
) -> None:
    """
    æ£€ç´¢å·¨æ½®å…¬å‘Šåˆ—è¡¨ï¼Œå¹¶å¯¹å‰ limit æ¡ç¬¦åˆæ¡ä»¶çš„å…¬å‘Šè¿›è¡Œæµå¼ PDF ä¸‹è½½ã€‚

    Args:
        code:                6 ä½è‚¡ç¥¨ä»£ç ã€‚
        name:                è‚¡ç¥¨åç§°ï¼ˆæ—¥å¿—ç”¨ï¼‰ã€‚
        category:            å·¨æ½®å…¬å‘Šç±»åˆ«ä»£ç ï¼ˆå¦‚ "category_ndbg_szsh"ï¼‰ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºå…¨æ–‡æœç´¢ã€‚
        limit:               æœ€å¤šä¸‹è½½çš„ PDF æ•°é‡ã€‚
        save_dir:            æœ¬åœ°ä¿å­˜ç›®å½•ã€‚
        searchkey:           å…¨æ–‡æœç´¢å…³é”®è¯ï¼ˆå¦‚ "è°ƒç ”"ï¼‰ï¼Œä¼ ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä¸ä½¿ç”¨å…³é”®è¯æœç´¢ã€‚
        use_investor_filter: æ˜¯å¦å¯ç”¨ INVESTOR_DOC_KEYWORDS ç²¾å‡†åè¿‡æ»¤ï¼ˆé’ˆå¯¹è°ƒç ”çºªè¦ï¼‰ã€‚
    """
    org_id: str = _get_org_id(code)
    # stock å‚æ•°æ ¼å¼ä¸º "code,orgId"ï¼ˆorgId ä¸ºç©ºæ—¶å·¨æ½®æ¥å£é™çº§å¤„ç†ä»å¯ç”¨ï¼‰
    stock_param: str = f"{code},{org_id}"

    # æ ¹æ®ä»£ç è‡ªåŠ¨é€‚é…äº¤æ˜“æ‰€åˆ—ï¼ˆszse=æ·±äº¤æ‰€ï¼Œsse=ä¸Šäº¤æ‰€ï¼‰
    column: str = "sse" if str(code).startswith("6") else "szse"

    payload: dict = {
        "pageNum": 1,
        "pageSize": 20,
        "column": column,
        "tabName": "fulltext",
        "stock": stock_param,
        "isHLtitle": "true",
    }
    if category:
        payload["category"] = category
    if searchkey:
        payload["searchkey"] = searchkey

    try:
        resp = safe_request(API_CONFIG["CNINFO_URL"], method="post", data=payload)
        if resp is None:
            logger.warning("[å·¨æ½®] %s(%s) å…¬å‘Šåˆ—è¡¨è¯·æ±‚å¤±è´¥ã€‚", name, code)
            return

        announcements: list[dict] = resp.json().get("announcements") or []
        if not announcements:
            logger.debug("[å·¨æ½®] %s(%s) ç±»åˆ«=%s æ— å…¬å‘Šç»“æœã€‚", name, code, category or searchkey)
            return

    except Exception as exc:
        logger.error("[å·¨æ½®] %s(%s) å…¬å‘Šåˆ—è¡¨è§£æå¤±è´¥: %s", name, code, exc)
        return

    downloaded_count: int = 0

    for ann in announcements:
        if downloaded_count >= limit:
            break

        raw_title: str = (
            str(ann.get("secName", "")) + "_" + str(ann.get("announcementTitle", ""))
        )
        adjunct_url: str = ann.get("adjunctUrl", "")

        if not adjunct_url:
            continue

        # â”€â”€ è¿‡æ»¤å™ªéŸ³å…¬å‘Š â”€â”€
        # è‹±æ–‡ç‰ˆå’Œæ‘˜è¦ç‰ˆä¸ä½œä¸ºåº•ç¨¿ä½¿ç”¨
        if "è‹±æ–‡" in raw_title or "æ‘˜è¦" in raw_title:
            continue

        # æŠ•èµ„è€…è°ƒç ”çºªè¦ç²¾å‡†åè¿‡æ»¤ï¼ˆä¿®å¤æ—§ä»£ç  searchkey è¢«æ¥å£ç«¯è¯¯æ€çš„é—®é¢˜ï¼‰
        if use_investor_filter:
            if not any(kw in raw_title for kw in INVESTOR_DOC_KEYWORDS):
                logger.debug("[å·¨æ½®] è·³è¿‡éè°ƒç ”ç±»å…¬å‘Š: %s", raw_title[:40])
                continue

        # â”€â”€ æ–‡ä»¶åå®‰å…¨åŒ– â”€â”€
        clean_title: str = re.sub(RE_ILLEGAL_FILENAME_CHARS, "", raw_title)
        clean_title = clean_title.replace(" ", "_").replace("\n", "").strip()
        # æˆªæ–­è¿‡é•¿æ–‡ä»¶åï¼Œé¿å… Windows è·¯å¾„é™åˆ¶
        if len(clean_title) > 120:
            clean_title = clean_title[:120]

        pdf_path: str = os.path.join(save_dir, f"{clean_title}.pdf")

        # â”€â”€ å¢é‡è·³è¿‡ï¼šæ–‡ä»¶å·²å­˜åœ¨ â”€â”€
        if os.path.exists(pdf_path):
            logger.info("[å·¨æ½®] â­ï¸  å·²å­˜åœ¨ï¼Œè·³è¿‡: %s", clean_title[:50])
            downloaded_count += 1
            continue

        # â”€â”€ æµå¼ä¸‹è½½ï¼ˆé˜² OOM æ ¸å¿ƒï¼‰â”€â”€
        download_url: str = API_CONFIG["CNINFO_DL_BASE"] + adjunct_url
        logger.info("[å·¨æ½®] â¬‡ï¸  å¼€å§‹ä¸‹è½½: %s...", clean_title[:50])

        try:
            written_bytes: int = 0
            with open(pdf_path, "wb") as pdf_file:
                for chunk in stream_download(download_url):
                    pdf_file.write(chunk)
                    written_bytes += len(chunk)

            if written_bytes == 0:
                # ä¸‹è½½å™¨æœªäº§ç”Ÿä»»ä½• chunkï¼Œè¯´æ˜è¿æ¥å¤±è´¥ï¼Œæ¸…ç†ç©ºæ–‡ä»¶
                os.remove(pdf_path)
                logger.warning("[å·¨æ½®] %s ä¸‹è½½å¤±è´¥ï¼ˆ0 å­—èŠ‚ï¼‰ã€‚", clean_title[:50])
                continue

            logger.info(
                "[å·¨æ½®] âœ… ä¸‹è½½å®Œæˆ: %s (%.1f KB)",
                clean_title[:50],
                written_bytes / 1024,
            )

            # â”€â”€ ä¸‹è½½æˆåŠŸåç«‹å³æå– RAG å¢é‡ä¿¡æ¯ â”€â”€
            _append_rag_to_panel(
                pdf_path=pdf_path,
                raw_title=raw_title,
                save_dir=save_dir,
            )

            downloaded_count += 1

        except Exception as exc:
            logger.error("[å·¨æ½®] %s å†™å…¥å¤±è´¥: %s", clean_title[:50], exc)
            # æ¸…ç†å†™äº†ä¸€åŠçš„æ®‹æŸæ–‡ä»¶
            if os.path.exists(pdf_path):
                os.remove(pdf_path)

        # ç¤¼è²Œå»¶è¿Ÿï¼Œé¿å…è§¦å‘å·¨æ½®é™é€Ÿ
        time.sleep(_DOWNLOAD_DELAY)


# ===========================================================================
# ç§æœ‰ï¼šæå– RAG ä¿¡æ¯å¹¶è¿½åŠ å†™å…¥å‚æ•°é¢æ¿
# ===========================================================================
def _append_rag_to_panel(pdf_path: str, raw_title: str, save_dir: str) -> None:
    """
    è°ƒç”¨ pdf_extractor æå–å…³é”®å¥ï¼Œè¿½åŠ å†™å…¥ 00_å‚æ•°é¢æ¿_å‘ç»™AI.mdã€‚

    ä»…å¯¹å¹´æŠ¥å’Œè°ƒç ”çºªè¦ç±» PDF è¿›è¡Œ RAG æå–ï¼ˆå…¶ä»–å­£æŠ¥è·³è¿‡ï¼Œé™ä½å™ªéŸ³ï¼‰ã€‚

    Args:
        pdf_path:  åˆšä¸‹è½½å®Œæˆçš„ PDF æœ¬åœ°è·¯å¾„ã€‚
        raw_title: åŸå§‹å…¬å‘Šæ ‡é¢˜ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æå– + è¿½åŠ æ ‡é¢˜ï¼‰ã€‚
        save_dir:  å‚æ•°é¢æ¿æ‰€åœ¨çš„ç›®å½•ã€‚
    """
    # åªå¯¹å«"å¹´æŠ¥"æˆ–"è°ƒç ”"å…³é”®è¯çš„ PDF åš RAG æå–
    should_extract: bool = any(kw in raw_title for kw in ("å¹´æŠ¥", "è°ƒç ”", "å¹´åº¦"))
    if not should_extract:
        return

    rag_sentences: list[str] = extract_rag_info_from_pdf(pdf_path)
    if not rag_sentences:
        return

    panel_path: str = os.path.join(save_dir, EXPORT_CONFIG["PANEL_FILENAME"])
    short_title: str = raw_title[:30]

    try:
        with open(panel_path, "a", encoding="utf-8") as f:
            f.write(f"\n\n### ğŸ“„ {short_title} - å¢é‡ RAG æçº¯æ•°æ®:\n")
            for sentence in rag_sentences:
                f.write(f"- {sentence}\n")
        logger.info("[RAG] å·²å°† %d æ¡å…³é”®å¥è¿½åŠ è‡³å‚æ•°é¢æ¿ã€‚", len(rag_sentences))
    except Exception as exc:
        logger.error("[RAG] å†™å…¥å‚æ•°é¢æ¿å¤±è´¥: %s", exc)
