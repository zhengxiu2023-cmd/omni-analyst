import akshare as ak
import pandas as pd
import requests
import os
import time
import re
import json
from datetime import datetime, timedelta

try:
    from pypdf import PdfReader
except ImportError:
    PdfReader = None

try:
    from pymongo import MongoClient
except ImportError:
    MongoClient = None
import warnings

# å±è”½åº•å±‚å¹²æ‰°ä¿¡å·ï¼Œä¿æŒç»ˆç«¯ç»å¯¹çº¯å‡€
warnings.filterwarnings('ignore')

# ==========================================
# The Omni-Analyst: ç»ˆææƒ…æŠ¥ç»ˆç«¯ v7.0 Singularity (å¥‡ç‚¹é™ä¸´ç‰ˆ)
# [é£æ§æ¥ç®¡] æ­»äº¡æ¢æ‰‹/æç«¯æš´æ¶¨/STæš´é›· è‡ªåŠ¨ç†”æ–­åˆ¤å®š
# [å®è§‚å®šæ ‡] Fä¹˜æ•°(æµåŠ¨æ€§)æ™ºèƒ½ç‰©ç†åˆ¤å®š
# [æµå¼å¼•æ“] å†›å·¥çº§å¤§æ–‡ä»¶ Chunk ä¸‹è½½ï¼Œæœç»å†…å­˜æº¢å‡º
# ==========================================

class OmniTerminal:
    def __init__(self):
        self.cninfo_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
        self.cninfo_dl_base = "http://static.cninfo.com.cn/"
        self.cninfo_stock_list = []  # å·¨æ½®è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ï¼ŒåŒ…å« orgId
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "X-Requested-With": "XMLHttpRequest"
        }
        
        # å®¡è®¡å¸ˆæ ¸å¿ƒé›·è¾¾è¯åº“
        self.kw_type1_tech = r"(AGI|å¤§æ¨¡å‹|å›ºæ€ç”µæ± |äººå½¢æœºå™¨äºº|è„‘æœºæ¥å£|é‡å­è®¡ç®—|å¸¸æ¸©è¶…å¯¼|é¢ è¦†æ€§|ä»£é™…å·®|å‚æ•°ç¢¾å‹|å½»åº•è§£å†³|å…¨çƒé¦–ä¸ª|é©å‘½æ€§|å¡è„–å­|è‡ªä¸»å¯æ§|ç®—åŠ›)"
        self.kw_type2_cycle = r"(ç°è´§.*æš´æ¶¨|å…¨çº¿æä»·|å°ç›˜ä¸æŠ¥|åœæ­¢æŠ¥ä»·|æ’äº§æ»¡è½½|åº“å­˜å‘Šæ€¥|äº§èƒ½.*å‡ºæ¸…|ä¾›ä¸åº”æ±‚|è¿ä»·é£™å‡|æ–­ä¾›|ç¿»å€|å†å²æ–°é«˜|æ»¡è´Ÿè·)"
        self.kw_policy_hard = r"(ä¸‡äº¿.*ä¸‹è¾¾|ä¸“é¡¹å€ºèµ„é‡‘åˆ°ä½|å¹¶è´­é‡ç»„|å‘æ”¹å§”.*æ ¸å‡†|é‡ç£…çªå‘|å›½å¸¸ä¼š|ç‰¹åˆ«å›½å€º|å…ç¨|è¡¥è´´è½åœ°|æ”¿ç­–å¼ºå¿ƒå‰‚)"
        self.kw_trap = r"(ç§‘å­¦å®¶.*è®ºæ–‡|æœ‰æœ›åœ¨æœªæ¥|æˆ–å°†|è§„åˆ’çº²è¦|æ„è§å¾æ±‚ç¨¿|å¹³ç¨³è¿è¡Œ|ä¸“å®¶é¢„æµ‹|å®éªŒå®¤é˜¶æ®µ|é€æ­¥å‘å¥½|ç†æ€§çœ‹å¾…)"
        
        self.db_collection = None
        if MongoClient:
            try:
                client = MongoClient("mongodb://localhost:27017/", serverSelectionTimeoutMS=2000)
                client.server_info() 
                self.db_collection = client['omni_analyst']['omni_targets']
            except Exception:
                self.db_collection = None

        self.use_llm = False
        self.llm_url = "http://localhost:11434/api/generate"
        try:
            if requests.get("http://localhost:11434/", timeout=1).status_code == 200:
                self.use_llm = True
        except: pass

    def _safe_request(self, url, method="get", max_retries=3, stream=False, **kwargs):
        """å†›å·¥çº§ç½‘ç»œé‡è¯•å¼•æ“ï¼Œæ”¯æŒæµå¼ä¸‹è½½ï¼Œè‡ªåŠ¨ä¼ é€’ headers"""
        # æµå¼ä¸‹è½½ï¼ˆå¤§æ–‡ä»¶ PDFï¼‰ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        timeout = 60 if stream else 15
        # ç¡®ä¿ headers è¢«æ­£ç¡®ä¼ é€’
        if 'headers' not in kwargs:
            kwargs['headers'] = self.headers
        for attempt in range(max_retries):
            try:
                if method == "get":
                    response = requests.get(url, timeout=timeout, stream=stream, **kwargs)
                else:
                    response = requests.post(url, timeout=timeout, stream=stream, **kwargs)
                response.raise_for_status()
                return response
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"  âš ï¸ ç½‘ç»œé‡è¯• ({attempt+1}/{max_retries}): {type(e).__name__}")
                    time.sleep(2 ** attempt)
                else:
                    return None

    def _get_stock_info(self, code):
        """å¤šæºå®¹ç¾è·å–å™¨ï¼šç²¾å‡†è·å–å•åªè‚¡ç¥¨ä¿¡æ¯"""
        result = {"name": code, "price": 0.0, "turnover": 0.0,
                  "pe_ttm": "N/A", "pb": "N/A", "success": False}

        # æº 1ï¼ˆä¸»åŠ›ï¼‰ï¼šä¸œè´¢ push2 è½»é‡å•è‚¡å®æ—¶è¡Œæƒ…æ¥å£
        # ç¨³å®šè¿”å›ï¼šä»·æ ¼/PE/PB/æ¢æ‰‹ç‡ï¼Œæ— éœ€æ‹‰å…¨é‡
        try:
            market = "1" if str(code).startswith("6") else "0"
            secid = f"{market}.{code}"
            em_url = "https://push2.eastmoney.com/api/qt/stock/get"
            params = {
                "secid": secid,
                "fields": "f43,f44,f45,f46,f57,f58,f60,f116,f162,f167,f168",
                # f43=æœ€é«˜ f44=æœ€ä½ f45=å¼€ç›˜ f46=æ˜¨æ”¶ f60=æœ€æ–°ä»·(ç›˜ä¸­å®æ—¶) f116=æ€»å¸‚å€¼
                # f162=PE_TTM f167=PB f168=æ¢æ‰‹ç‡
                "ut": "fa5fd1943c7b386f172d6893dbfba10b",
                "fltt": 2, "invt": 2
            }
            resp = requests.get(em_url, params=params,
                                headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
            if resp.status_code == 200:
                data = resp.json().get("data", {})
                if data.get("f60") is not None:
                    result['name'] = data.get('f58', code)
                    result['price'] = float(data.get('f60', 0))
                    result['turnover'] = float(data.get('f168', 0))
                    pe = data.get('f162')
                    pb = data.get('f167')
                    result['pe_ttm'] = round(float(pe), 2) if pe and pe != "-" else "N/A"
                    result['pb'] = round(float(pb), 2) if pb and pb != "-" else "N/A"
                    result['success'] = True
                    # ä¿å­˜æ€»å¸‚å€¼ç”¨äºåç»­è®¡ç®— EPS
                    result['total_mv'] = float(data.get('f116', 0) or 0)
                    print(f"  âœ… [å®¹ç¾æº1] ä¸œè´¢å®æ—¶è¡Œæƒ…å‘½ä¸­: {result['name']} | "
                          f"ä»·æ ¼={result['price']} PE_TTM={result['pe_ttm']} PB={result['pb']} "
                          f"æ¢æ‰‹={result['turnover']}%")
        except Exception as e:
            print(f"  âš ï¸ [å®¹ç¾æº1] ä¸œè´¢å®æ—¶æ¥å£å¤±è´¥: {type(e).__name__}")

        # æº 2ï¼ˆåç§°å…œåº•ï¼‰ï¼šstock_individual_info_em åªç”¨äºè¡¥å……ä¸­æ–‡åç§°
        if result['name'] == code:
            try:
                info_df = ak.stock_individual_info_em(symbol=code)
                if not info_df.empty:
                    name_row = info_df[info_df['item'] == 'è‚¡ç¥¨ç®€ç§°']
                    if not name_row.empty:
                        result['name'] = name_row['value'].values[0]
                    if result['price'] == 0.0:
                        p_row = info_df[info_df['item'] == 'æœ€æ–°']
                        if not p_row.empty:
                            result['price'] = float(p_row['value'].values[0])
                    if not result['success']:
                        result['success'] = result['price'] > 0
                    print(f"  âœ… [å®¹ç¾æº2] ä¸ªè‚¡ä¿¡æ¯å…œåº•: åç§°={result['name']}")
            except Exception as e:
                print(f"  âš ï¸ [å®¹ç¾æº2] ä¸ªè‚¡ä¿¡æ¯æ¥å£å¤±è´¥: {type(e).__name__}")

        return result


    def _get_cninfo_orgid(self, code):
        """ä»å·¨æ½®èµ„è®¯ç½‘è·å–è‚¡ç¥¨çš„ orgIdï¼Œç”¨äºæ„å»ºæ­£ç¡®çš„ stock æŸ¥è¯¢å‚æ•°"""
        # ç¼“å­˜æœºåˆ¶ï¼šåªæ‹‰å–ä¸€æ¬¡è‚¡ç¥¨åˆ—è¡¨
        if not self.cninfo_stock_list:
            try:
                res = self._safe_request('http://www.cninfo.com.cn/new/data/szse_stock.json', method='get')
                if res:
                    self.cninfo_stock_list = res.json().get('stockList', [])
                    print(f"  ğŸ“Š å·¨æ½®è‚¡ç¥¨åº“å·²åŠ è½½: {len(self.cninfo_stock_list)} åª")
            except Exception:
                pass
        # æŸ¥æ‰¾ç›®æ ‡è‚¡ç¥¨çš„ orgId
        for s in self.cninfo_stock_list:
            if s.get('code') == str(code):
                return s.get('orgId', '')
        return ''

    # ----------------------------------------
    # æ¨¡å—ä¸€ï¼šå…ˆçŸ¥çŸ©é˜µ (æºå¤´æƒ…æŠ¥æåº¦æŒ–æ˜)
    # ----------------------------------------
    def module_1_intel_radar(self):
        print("\n" + "â˜…"*75)
        print(" ğŸŒŒ [å¥‡ç‚¹é›·è¾¾] å¯åŠ¨ï¼æ­£åœ¨å‘å…¨ç½‘å€¾æ³»ä¾¦æµ‹æ¢é’ˆï¼ŒæŒ–æ˜é«˜ç»´ Alpha æ•°æ®æº...")
        if self.use_llm: print(" ğŸ§  [LLM] æ£€æµ‹åˆ°æœ¬åœ° Ollama å¼•æ“ï¼Œç¥ç»å…ƒç½‘ç»œå·²æ¥ç®¡è¿‡æ»¤æœºåˆ¶ï¼")
        else: print(" âš™ï¸ [LLM] æœªæ£€æµ‹åˆ°æœ¬åœ°å¤§æ¨¡å‹ï¼Œé™çº§ä½¿ç”¨ç‰©ç†æ­£åˆ™æ³•åˆ™ã€‚")
        if self.db_collection is not None: print(" ğŸ”Œ [MongoDB] æœ¬åœ°äº‘ç«¯æ•°æ®åº“è¿æ¥æˆåŠŸã€‚")
        print("â˜…"*75)
        valuable_news = []
        
        try:
            print(" [1/4] ğŸ’° æ­£åœ¨é€è§† [é¾™è™æ¦œæŠ¢ç­¹] ä¸ [èªæ˜é’±è°ƒç ”] ...")
            try:
                df_jg = ak.stock_jgdy_tj_em()
                hot_jg = df_jg[df_jg['æ¥å¾…æœºæ„æ•°é‡'] > 100].head(4)
                for _, row in hot_jg.iterrows():
                    msg = f"ç»å¯¹æš—æµï¼ã€{row['å…¬å¸åç§°']}ã€‘è¿‘æœŸé­ {row['æ¥å¾…æœºæ„æ•°é‡']} å®¶é¡¶çº§æœºæ„è¸ç ´é—¨æ§›è°ƒç ”ã€‚"
                    valuable_news.append({'time': row['æœ€æ–°è°ƒç ”æ—¥æœŸ'], 'tags': "ğŸ¯ [æœºæ„å»ºä»“å‰å…†]", 'title': msg, 'source': "è°ƒç ”ç©¿é€", 'score': 1})
                
                start_d = (datetime.now() - timedelta(days=15)).strftime("%Y%m%d")
                end_d = datetime.now().strftime("%Y%m%d")
                df_lhb = ak.stock_lhb_jgmmtj_em(start_date=start_d, end_date=end_d)
                if not df_lhb.empty:
                    df_lhb['æœºæ„å‡€ä¹°é¢'] = pd.to_numeric(df_lhb['æœºæ„å‡€ä¹°é¢'], errors='coerce')
                    hot_lhb = df_lhb[df_lhb['æœºæ„å‡€ä¹°é¢'] > 60000000].head(5) 
                    for _, row in hot_lhb.iterrows():
                        msg = f"çœŸé‡‘ç™½é“¶å¼ºç›–ç« ï¼ã€{row['è‚¡ç¥¨åç§°']}({row['è‚¡ç¥¨ä»£ç ']})ã€‘è¿‘æœŸé­æœºæ„å¸­ä½æš´åŠ›å‡€ä¹°å…¥ {(row['æœºæ„å‡€ä¹°é¢']/100000000):.2f} äº¿å…ƒï¼"
                        valuable_news.append({'time': "è¿‘æœŸé¾™è™æ¦œ", 'tags': "ğŸ”¥ [å¸­ä½æš´åŠ›æŠ¢ç­¹]", 'title': msg, 'source': "é¾™è™æ¦œé›·è¾¾", 'score': 2})
            except: pass

            print(" [2/4] ğŸ­ æ­£åœ¨å—…æ¢ [äº§ä¸šç°è´§æ–­è£‚] ä¸ [æµ·å¤–ç§‘æŠ€å¥‡ç‚¹]...")
            try:
                df_cls = ak.stock_info_global_cls().head(120)
                for _, row in df_cls.iterrows():
                    self._filter_and_append(row['æ ‡é¢˜'] + " " + row['å†…å®¹'], row['å‘å¸ƒæ—¶é—´'], row['æ ‡é¢˜'], "å…¨ç½‘å¿«è®¯", valuable_news)
            except: pass

            print(" [3/4] ğŸ›ï¸ æ­£åœ¨é€†æ¨ [å›½å®¶å®è§‚æ„å¿—] (T-3æ—¥ç©¿é€)...")
            for days_back in range(3):
                date_str = (datetime.now() - timedelta(days=days_back)).strftime("%Y%m%d")
                try:
                    df_cctv = ak.news_cctv(date=date_str)
                    if not df_cctv.empty:
                        for _, row in df_cctv.iterrows():
                            self._filter_and_append(row['content'], date_str, row['title'], f"æ–°é—»è”æ’­(T-{days_back})", valuable_news)
                        break 
                except: continue
            
            print(" [4/4] ğŸ’¸ æ­£åœ¨ç›‘æ§ [Aè‚¡ä¸»çº¿èµ„é‡‘] æš´åŠ¨æ¿å—...")
            try:
                df_board = ak.stock_board_industry_name_em()
                hot_boards = df_board[df_board['æ¶¨è·Œå¹…'] > 4.5].head(3)
                for _, row in hot_boards.iterrows():
                    msg = f"ä¸»çº¿ç¡®è®¤ï¼ã€{row['æ¿å—åç§°']}ã€‘ä»Šæ—¥æš´æ¶¨ {row['æ¶¨è·Œå¹…']}%, å±äºå…¨å¸‚åœºç»å¯¹å…±è¯†ï¼"
                    valuable_news.append({'time': "ä»Šæ—¥ç›˜é¢", 'tags': "ğŸ“ˆ [èµ„é‡‘å…±æŒ¯é«˜æ½®]", 'title': msg, 'source': "èµ„é‡‘é›·è¾¾", 'score': 2})
            except: pass

            if not valuable_news:
                print("\nâ˜• çŸ©é˜µé™é»˜ã€‚å½“å‰æœªæŒ–æ˜åˆ°å…·å¤‡ã€è¶…æ™¯æ°”çº§åˆ«ã€‘çš„ä¿¡æ¯ï¼Œç©ºä»“ç­‰å¾…ã€‚")
                return
                
            valuable_news.sort(key=lambda x: x.get('score', 0), reverse=True)
                
            print("\n" + "!"*75)
            print(f" ğŸš¨ æŒ–æ˜å®Œæ¯•ï¼šæç‚¼å‡º {len(valuable_news)} æ¡ã€é«˜èƒ½ Alpha æºå¤´æƒ…æŠ¥ã€‘")
            print("!"*75)
            for news in valuable_news[:20]:
                star_str = "â˜…" * news.get('score', 1)
                print(f"[{news['time']}] {star_str} | æ¥æº: {news['source']} | {news['tags']}\nğŸ“Œ {news['title']}\n" + "-"*60)
            
            print("\nğŸ’¡ å®¡è®¡å¸ˆæŒ‡ä»¤ï¼šé‡ç‚¹æ‰“å‡»å¸¦æœ‰ [â˜…â˜…] æ˜Ÿå·çš„æ ‡çš„ã€‚æ‰¾åˆ°ç›®æ ‡ä»£ç åï¼Œæ‰§è¡Œ [æ¨¡å— 2]ã€‚")
                
        except Exception as e:
            print(f"çŸ©é˜µé­é‡æœªçŸ¥å¼‚å¸¸: {e}")

    def _filter_and_append(self, text, time_str, title, source, result_list):
        tags = []
        score = 1
        text_full = str(text) + str(title)
        
        if self.use_llm:
            if re.search(self.kw_trap, text_full): return 
            prompt = f"è¯·åˆ¤æ–­ä¸‹é¢çš„æ–°é—»æ ‡é¢˜æ˜¯å¦åŒ…å«ï¼š1.æ”¹å˜è¡Œä¸šçš„é¢ è¦†æ€§æŠ€æœ¯çªç ´ã€‚2.ä¸¥é‡çš„ä¾›éœ€æ–­è£‚æˆ–ç°è´§æš´æ¶¨æ»¡äº§ã€‚3.å›½å®¶çº§å®è§‚æ”¿ç­–åˆºæ¿€ã€‚\nå¦‚æœåŒ…å«ï¼Œåªè¾“å‡º'<SCORE:2>'ã€‚å¦‚æœä¸ç›¸å…³æˆ–å¹³åº¸ï¼Œåªè¾“å‡º'<SCORE:0>'ã€‚\næ ‡é¢˜ï¼š{title}"
            try:
                res = requests.post(self.llm_url, json={"model": "qwen2.5:7b", "prompt": prompt, "stream": False}, timeout=1.5)
                if res.status_code == 200:
                    ans = res.json().get('response', '')
                    if "<SCORE:0>" in ans: return
                    elif "<SCORE:2>" in ans:
                        score = 2
                        tags.append("ğŸ§  [LLM:æ ¸å¿ƒå¥‡ç‚¹å…±æŒ¯]")
            except: pass
            
        if not tags: # Fallback to regex
            if re.search(self.kw_trap, text_full): return 
            if re.search(self.kw_type1_tech, text_full): tags.append("ğŸš€ [Type1:é¢ è¦†å¥‡ç‚¹]")
            if re.search(self.kw_type2_cycle, text_full): tags.append("ğŸ”¥ [Type2:ç°è´§æ–­è£‚]")
            if re.search(self.kw_policy_hard, text_full): tags.append("ğŸ›ï¸ [Type3:å®è§‚çœŸé‡‘]")
            if len(tags) >= 2: score = 2
        
        if tags and not any(title == item['title'] for item in result_list):
            result_list.append({'time': time_str, 'tags': " | ".join(tags), 'title': title, 'source': source, 'score': score})

    # ----------------------------------------
    # æ¨¡å—äºŒï¼šæå®¢çº§æ·±åº¦åº•æ–™æ‰“åŒ… (é£æ§å…¨è‡ªåŠ¨æ¥ç®¡)
    # ----------------------------------------
    def module_2_audit_prep(self, target_code):
        print(f"\nğŸ“¥ [æ·±åº¦ç©¿é€å®¡è®¡å‡†å¤‡] -> é‡å­é”æ­»ç›®æ ‡: {target_code}")
        try:
            # ===== é˜¶æ®µ 1: å¤šæºå®¹ç¾è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ =====
            print("\nğŸ” [é˜¶æ®µ1] å¯åŠ¨å¤šæºå®¹ç¾è·å–å™¨...")
            stock_info = self._get_stock_info(target_code)
            spot_df = stock_info.get('spot_df', pd.DataFrame())  # å¯èƒ½ä¸ºç©º

            target_name = stock_info['name']
            blind_mode = not stock_info['success']

            if blind_mode:
                print("âš ï¸ [ç›²é™æ¨¡å¼] æ‰€æœ‰è¡Œæƒ…æ¥å£å‡å¤±è´¥ï¼Œå¯ç”¨å¼ºåˆ¶ä¸‹è½½æ¨¡å¼ã€‚")
                print("   â†’ å°†è·³è¿‡å‚æ•°é¢æ¿ç»„è£…ï¼Œä½†è´¢æŠ¥ PDF ä¸‹è½½ä¸å—å½±å“ã€‚")
                target_name = target_code  # ç”¨ä»£ç ä½œä¸ºåç§°

            # æ„é€ ä¸€ä¸ªå…¼å®¹çš„ target_info Seriesï¼ˆç”¨äº _generate_parametersï¼‰
            target_info = pd.Series({
                'åç§°': target_name,
                'æœ€æ–°ä»·': stock_info['price'],
                'æ¢æ‰‹ç‡': stock_info['turnover'],
                'å¸‚ç›ˆç‡-åŠ¨æ€': stock_info['pe_ttm'],
                'å¸‚å‡€ç‡-åŠ¨æ€': stock_info['pb'],
            })

            # ===== é˜¶æ®µ 2: è¡Œä¸šä¸ç«å¯¹æ¢æµ‹ï¼ˆå…è®¸å¤±è´¥ï¼‰ =====
            rival_code, rival_name, core_industry = None, None, "æœªçŸ¥"
            if not blind_mode:
                try:
                    ind_info = ak.stock_individual_info_em(symbol=target_code)
                    core_industry = ind_info[ind_info['item'] == 'è¡Œä¸š']['value'].values[0]
                    all_boards = ak.stock_board_industry_name_em()
                    matched_board = next((b for b in all_boards['æ¿å—åç§°'] if core_industry in b or b in core_industry), None)
                    
                    if matched_board:
                        cons_df = ak.stock_board_industry_cons_em(symbol=matched_board).sort_values(by='æ€»å¸‚å€¼', ascending=False)
                        for _, r in cons_df.iterrows():
                            if str(r['ä»£ç ']) != target_code:
                                rival_code, rival_name = str(r['ä»£ç ']), r['åç§°']
                                print(f"ğŸ¯ å¯»æ•Œé›·è¾¾é”å®š: ã€{matched_board}ã€‘æœ€å¼ºå¯¹æ‰‹ -> {rival_name}({rival_code})")
                                break
                except:
                    pass

            core_business = f"ä¸»è¥æ¿å—: ã€{core_industry}ã€‘"
            recent_news_str = ""
            if not blind_mode:
                try:
                    profile = ak.stock_profile_cninfo(symbol=target_code)
                    if not profile.empty and 'ä¸»è¥ä¸šåŠ¡' in profile.columns:
                        business_desc = str(profile['ä¸»è¥ä¸šåŠ¡'].iloc[0]).replace('\n', '')
                        core_business += f" | ä¸šåŠ¡ç©¿é€: {business_desc[:80]}..."
                    
                    news_df = ak.stock_news_em(symbol=target_code).head(2)
                    if not news_df.empty:
                        recent_news_str = " | ".join(news_df['æ–°é—»æ ‡é¢˜'].tolist())
                except: pass
            
            final_catalyst_str = core_business
            if recent_news_str:
                final_catalyst_str += f"\n**ç³»ç»Ÿè‡ªåŠ¨æ•è·è¿‘æœŸå‚¬åŒ–å‰‚ï¼š** {recent_news_str}"

            # ç»Ÿä¸€è¾“å‡ºç›®å½•: company_info/{name}_{code}/ ï¼ˆä¸å«æ—¥æœŸï¼Œæ–¹ä¾¿å¢é‡æ›´æ–°ï¼‰
            base_dir = "company_info"
            save_dir = os.path.join(base_dir, f"{target_name}_{target_code}")
            if not os.path.exists(save_dir):
                os.makedirs(save_dir)
            else:
                print(f"  ğŸ“‚ å·²å­˜åœ¨æ–‡ä»¶å¤¹ã€{save_dir}ã€‘ï¼Œå°†è¿›è¡Œå¢é‡åˆå¹¶ã€‚")

            # ===== é˜¶æ®µ 3: å‚æ•°é¢æ¿ç»„è£…ï¼ˆå…è®¸å¤±è´¥ï¼Œä¸é˜»æ–­åç»­ï¼‰ =====
            if not blind_mode:
                try:
                    self._generate_parameters(target_code, target_name, target_info, final_catalyst_str, save_dir, spot_df)
                except Exception as e:
                    print(f"âš ï¸ å‚æ•°é¢æ¿ç»„è£…å—æŸ (ä¸å½±å“è´¢æŠ¥ä¸‹è½½): {e}")
            else:
                print("â­ï¸ [ç›²é™] è·³è¿‡å‚æ•°é¢æ¿ç»„è£…ã€‚")

            # ===== é˜¶æ®µ 4: å¼ºåˆ¶æ‰§è¡Œè´¢æŠ¥ä¸‹è½½ï¼ˆæ°¸è¿œæ‰§è¡Œï¼Œä¸å—å‰é¢å½±å“ï¼‰ =====
            print("\nğŸ“¥ æ­£åœ¨ä½¿ç”¨æµå¼å¼•æ“æŠ½å–å·¨æ½® PDF åº•ç¨¿ (æœç»å†…å­˜æº¢å‡º)...")
            self._dl_cninfo(target_code, "category_ndbg_szsh", 2, save_dir)   # å¹´æŠ¥ï¼ˆæœ€è¿‘2ä»½ï¼‰
            self._dl_cninfo(target_code, "category_bndbg_szsh", 2, save_dir)  # åŠå¹´æŠ¥
            self._dl_cninfo(target_code, "category_sjdbg_szsh", 2, save_dir)  # ä¸‰å­£æŠ¥
            self._dl_cninfo(target_code, "category_yjdbg_szsh", 1, save_dir)  # ä¸€å­£æŠ¥
            self._dl_cninfo(target_code, "", 5, save_dir, searchkey="è°ƒç ”")  # æŠ•èµ„è€…çºªè¦/è°ƒç ”æ¥å¾…ï¼ˆå…¨åˆ†ç±»æœç´¢ï¼‰
            if rival_code:
                self._dl_cninfo(rival_code, "category_ndbg_szsh", 1, save_dir)  # ç«å¯¹å¹´æŠ¥
                self._dl_cninfo(rival_code, "category_sjdbg_szsh", 1, save_dir)  # ç«å¯¹æœ€æ–°å­£æŠ¥

            print(f"\nğŸ‰ æˆ˜æœ¯åº•æ–™æ‰“åŒ…å®Œæˆï¼è¯·å‰å¾€è·¯å¾„æŸ¥æ”¶: [{save_dir}]")
            print("ğŸ’¡ ç»ˆææŒ‡ä»¤ï¼šç›´æ¥å…¨é€‰å¤åˆ¶ã€00_å‚æ•°é¢æ¿_å‘ç»™AI.mdã€çš„å†…å®¹ï¼Œä½œä¸ºç¡¬æ•°æ®å–‚ç»™æˆ‘ï¼")

        except Exception as e:
            print(f"ç³»ç»Ÿé­é‡å¼‚å¸¸: {e}")

    def _generate_parameters(self, code, name, stock_data, core_business, save_dir, spot_df=None):
        print("âš™ï¸ æ­£åœ¨æ‰§è¡Œé«˜ç»´å‚æ•°é‡ç»„ä¸ Phase V é£æ§æ¥ç®¡...")
        try:
            # 1. å®è§‚æµåŠ¨æ€§ F ä¹˜æ•°æ™ºèƒ½åˆ¤å®šï¼ˆç”¨ push2 å¤§ç›˜æ¥å£ï¼Œç›´æ¥å¯é ï¼‰
            raw_market_vol = 1.0
            try:
                em_mkt_url = "https://push2.eastmoney.com/api/qt/ulist.np/get"
                em_mkt_params = {
                    "fltt": 2, "invt": 2,
                    "fields": "f12,f6",  # f6=å…¨å¤©æˆäº¤é¢
                    "secids": "1.000001,0.399001,1.000016,0.399006",
                    "ut": "b2884a393a59ad64002292a3e90d46a5"
                }
                mkt_resp = requests.get(em_mkt_url, params=em_mkt_params,
                                        headers={"User-Agent": "Mozilla/5.0"}, timeout=8)
                mkt_data = mkt_resp.json().get("data", {}).get("diff", [])
                raw_market_vol = sum(float(d.get("f6", 0) or 0) for d in mkt_data if d) / 1e12
                print(f"  âœ… push2 å¤§ç›˜æ€»æˆäº¤é¢: {raw_market_vol:.2f} ä¸‡äº¿")
            except Exception:
                pass  # ä¿ç•™é»˜è®¤å¸¸æ€å€¼ 1.0
            if raw_market_vol >= 1.5:
                market_vol_status = f"{raw_market_vol:.2f} ä¸‡äº¿ (ç–¯ç‰›/æ ¸å¿ƒèµ·èˆ -> Fä¹˜æ•°ç¡¬ç¼–ç : x1.2)"
            elif raw_market_vol <= 0.8:
                market_vol_status = f"{raw_market_vol:.2f} ä¸‡äº¿ (å†°ç‚¹/æµåŠ¨æ€§æ¯ç«­ -> Fä¹˜æ•°ç¡¬ç¼–ç : x0.8)"
            else:
                market_vol_status = f"{raw_market_vol:.2f} ä¸‡äº¿ (å¸¸æ€éœ‡è¡ -> Fä¹˜æ•°ç¡¬ç¼–ç : x1.0)"

            # å®‰å…¨è·å–è…¨æƒ…å­—æ®µï¼ˆå…¼å®¹å®¹ç¾æºå’Œå…¨é‡è¡Œæƒ…å°†ä¸åŒçš„å­—æ®µå‡½ï¼‰
            def _safe_val(series, *keys, default='N/A'):
                for k in keys:
                    v = series.get(k, None) if hasattr(series, 'get') else getattr(series, k, None)
                    if v is not None and str(v) not in ('', 'nan', 'None', 'N/A'):
                        return v
                return default

            p_now_raw = _safe_val(stock_data, 'æœ€æ–°ä»·', 'æ”¶ç›˜', default=0)
            try:
                p_now = float(p_now_raw)
            except (ValueError, TypeError):
                p_now = 0.0
            turnover = _safe_val(stock_data, 'æ¢æ‰‹ç‡', default='N/A')
            pe_ttm = _safe_val(stock_data, 'å¸‚ç›ˆç‡-åŠ¨æ€', 'å¸‚ç›ˆç‡', default='N/A')
            pb = _safe_val(stock_data, 'å¸‚å‡€ç‡-åŠ¨æ€', 'å¸‚å‡€ç‡', default='N/A')
            
            # 2. æ·±åº¦å†å²é‡æ„ - push2 kline ä¸‰å¹´æ—¥çº¿ï¼ˆå¸¦é‡è¯•ï¼‰
            p_min_3y, rise_from_bottom, price_percentile = p_now, 0.0, 100.0
            death_turnover_warning = "[å®‰å…¨]"
            extreme_rise_warning = ""

            try:
                market_prefix = "1" if str(code).startswith("6") else "0"
                secid = f"{market_prefix}.{code}"
                kline_url = "https://push2his.eastmoney.com/api/qt/stock/kline/get"
                kline_params = {
                    "secid": secid, "fields1": "f1,f2,f3,f4,f5,f6",
                    "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61",
                    "klt": 101, "fqt": 1,
                    "beg": (datetime.now() - timedelta(days=365*3)).strftime("%Y%m%d"),
                    "end": datetime.now().strftime("%Y%m%d"),
                    "ut": "fa5fd1943c7b386f172d6893dbfba10b"
                }
                # å¸¦é‡è¯•çš„ kline è·å–ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
                klines = []
                for attempt in range(3):
                    try:
                        sess = requests.Session()
                        kline_resp = sess.get(kline_url, params=kline_params,
                                              headers={"User-Agent": "Mozilla/5.0"},
                                              timeout=15)
                        kline_data = kline_resp.json().get("data", {}) or {}
                        klines = kline_data.get("klines", []) or []
                        if klines:
                            break
                    except Exception:
                        time.sleep(1)
                if klines:
                    lows  = [float(k.split(',')[4]) for k in klines]
                    highs = [float(k.split(',')[3]) for k in klines]
                    turnover_list = [float(k.split(',')[10]) for k in klines if len(k.split(',')) > 10]
                    p_min_3y = min(lows)
                    p_max_3y = max(highs)
                    price_percentile = ((p_now - p_min_3y) / (p_max_3y - p_min_3y) * 100) if p_max_3y != p_min_3y else 0
                    rise_from_bottom = ((p_now - p_min_3y) / p_min_3y * 100) if p_min_3y > 0 else 0
                    if turnover_list:
                        max_t5 = max(turnover_list[-5:])
                        if max_t5 > 40 and 'N' not in name and 'C' not in name:
                            death_turnover_warning = f"âš ï¸ [è§¦å‘æ­»äº¡æ¢æ‰‹æ¸…ä»“çº¿! è¿‘5æ—¥æå¤§æ¢æ‰‹ç‡è¾¾ {max_t5}%]"
                    if len(lows) >= 60:
                        min_60d = min(lows[-60:])
                        rise_60d = ((p_now - min_60d) / min_60d * 100) if min_60d > 0 else 0
                        if rise_60d > 150:
                            extreme_rise_warning = f" (âš ï¸ è­¦æŠ¥ï¼šè¿‘60æ—¥å·²æç«¯æš´æ¶¨ {rise_60d:.1f}%ï¼Œæåº¦é€æ”¯ï¼)"
                    print(f"  âœ… kline ä¸‰å¹´å†å²({len(klines)}æ¡): æœ€ä½={p_min_3y}, åˆ†ä½={price_percentile:.1f}%")
                else:
                    print("  âš ï¸ kline ä¸‰æ¬¡é‡è¯•å‡å¤±è´¥ï¼Œæ­·å²åˆ†ä½ä½¿ç”¨é»˜è®¤å€¼")
            except Exception as ek:
                print(f"  âš ï¸ kline å†å²æ¥å£å¤±è´¥: {type(ek).__name__}")

            holder_trend = "æ•°æ®ç¼ºå¤±"
            try:
                gdhs_df = ak.stock_zh_a_gdhs_detail_em(symbol=code)
                if not gdhs_df.empty:
                    # å®é™…åˆ—åæ˜¯ 'è‚¡ä¸œæˆ·æ•°-å¢å‡æ¯”ä¾‹'
                    change_col = next((col for col in ['è‚¡ä¸œæˆ·æ•°-å¢å‡æ¯”ä¾‹', 'æˆ·æ•°å˜åŒ–æ¯”ä¾‹', 'æœ¬æ¬¡å˜åŠ¨æ¯”ä¾‹', 'å˜åŠ¨æ¯”ä¾‹'] if col in gdhs_df.columns), None)
                    if change_col:
                        latest_change = gdhs_df.iloc[-1][change_col]  # æœ€æ–°ä¸€æœŸï¼ˆæœ€åä¸€è¡Œï¼‰
                        if isinstance(latest_change, str): latest_change = float(latest_change.replace('%', '').strip())
                        latest_change = float(latest_change)
                        if latest_change > 5: holder_trend = f"å¢åŠ  {latest_change:.2f}% (âš ï¸ ä¸»åŠ›æ´¾å‘/æ•£æˆ·æ¥ç›˜è­¦æŠ¥)"
                        elif latest_change < -5: holder_trend = f"å‡å°‘ {abs(latest_change):.2f}% (ğŸ“ˆ ä¸»åŠ›å¸ç­¹/ç­¹ç é«˜åº¦é›†ä¸­)"
                        else: holder_trend = f"{latest_change:.2f}% (ç­¹ç å¹³ç¨³)"
                    else:
                        holder_trend = f"åˆ—åæœªåŒ¹é…, å¯ç”¨åˆ—: {list(gdhs_df.columns)}"
            except: pass

            eps_forecast = "[æå–å¤±è´¥ï¼Œéœ€è‡ªè¡Œç ”åˆ¤]"
            try:
                # é€šè¿‡ PE_TTM å’Œå½“å‰è‚¡ä»·åç®— EPS_TTM
                if pe_ttm != 'N/A' and p_now > 0:
                    pe_val = float(pe_ttm)
                    if pe_val > 0:
                        eps_ttm = round(p_now / pe_val, 2)
                        eps_forecast = f"EPS_TTM={eps_ttm} (ç”± P/PE åç®—ï¼Œæœªæ¥å¹´åº¦é¢„æµ‹éœ€å‚è€ƒåˆ¸å•†ç ”æŠ¥)"
                        print(f"  âœ… EPS_TTMåç®—: {eps_ttm}")
            except Exception as e:
                print(f"  [EPS] è­¦å‘Š: {e}")

            # è´¢åŠ¡é›·åŒºåˆ¤å®š
            st_warning = "âš ï¸ [è´¢åŠ¡æš´é›·åˆ¤å®š: æ˜¯(ST/è´Ÿå‡€èµ„äº§ï¼Œéœ€å³åˆ»ç†”æ–­ï¼)]" if ('ST' in name or str(pb).startswith('-')) else "[é€šè¿‡]"

            # æ„å»ºå‚æ•°å­—æ®µåˆ—è¡¨ï¼Œæ¯ä¸ªå­—æ®µå¸¦ä¿¡å¿ƒç­‰çº§ (high=ç¨‹åºè·å–åˆ°æœ‰æ•ˆæ•°æ®, low=ä½¿ç”¨é»˜è®¤å€¼/å¤±è´¥)
            fields = [
                ("æ ‡çš„åç§°/ä»£ç ", f"{name} ({code}) {st_warning}", "high"),
                ("å½“å‰ä»·æ ¼ (P_now)", f"{p_now:.2f}", "high" if p_now > 0 else "low"),
                ("è¿‘3å¹´æœ€ä½ä»· (P_min_3y, å‰å¤æƒ)", f"{p_min_3y:.2f} (è‡ªåº•éƒ¨å·²åå¼¹ {rise_from_bottom:.1f}%){extreme_rise_warning}",
                 "high" if p_min_3y != p_now else "low"),
                ("å½“å‰ä»·æ ¼å†å²åˆ†ä½ (Price_Percentile)", f"{price_percentile:.1f}%",
                 "high" if p_min_3y != p_now else "low"),
                ("æœ€æ–°é™æ€/åŠ¨æ€å¸‚ç›ˆç‡ (PE_TTM)", f"{pe_ttm}", "high" if pe_ttm != 'N/A' else "low"),
                ("æœ€æ–°å¸‚å‡€ç‡ (PB)", f"{pb}", "high" if pb != 'N/A' else "low"),
                ("æœªæ¥ä¸‰å¹´é¢„æœŸæ¯è‚¡æ”¶ç›Š (EPS_Y1, EPS_Y2, EPS_Y3)", f"{eps_forecast}",
                 "low" if "æå–å¤±è´¥" in eps_forecast or "åç®—" in eps_forecast else "high"),
                ("æ ¸å¿ƒäº§å“ç°è´§/æœŸè´§ä»·æ ¼è¶‹åŠ¿ æˆ– è®¢å•é”€é‡",
                 "[è¯·ç»“åˆæºå¤´æƒ…æŠ¥æˆ– PDF çºªè¦äººå·¥å¡«å…¥ï¼šä¾‹å¦‚äº§å“æ­£åœ¨æ¶¨ä»·ï¼Œæˆ–äº§èƒ½æ»¡è½½]", "low"),
                ("ä»Šæ—¥æ¢æ‰‹ç‡ (Turnover)", f"{turnover}% {death_turnover_warning}",
                 "high" if turnover not in (0, 0.0, 'N/A') else "low"),
                ("ä¸¤å¸‚ä»Šæ—¥æ€»æˆäº¤é¢ (Market_Vol)", f"{market_vol_status}", "high" if raw_market_vol != 1.0 else "low"),
                ("æœ€æ–°è‚¡ä¸œæˆ·æ•°å˜åŒ–", f"{holder_trend}", "high" if "ç¼ºå¤±" not in holder_trend else "low"),
                ("æ ¸å¿ƒå‚¬åŒ–å‰‚/è¡Œä¸šèƒŒæ™¯", f"{core_business}", "high"),
            ]

            # è¯»å–æ—§é¢æ¿æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œè§£æä¸º {å­—æ®µå: å€¼} å­—å…¸
            panel_path = os.path.join(save_dir, "00_å‚æ•°é¢æ¿_å‘ç»™AI.md")
            old_fields = {}
            old_rag = ""
            if os.path.exists(panel_path):
                try:
                    with open(panel_path, "r", encoding="utf-8") as rf:
                        old_content = rf.read()
                    # æå–å¢é‡ RAG æ•°æ®
                    rag_marker = "### ğŸ“„"
                    rag_idx = old_content.find(rag_marker)
                    if rag_idx != -1:
                        old_rag = "\n" + old_content[rag_idx:]
                    # è§£ææ—§å­—æ®µ
                    for line in old_content.split("\n"):
                        line = line.strip()
                        if line.startswith("**") and "ï¼š**" in line:
                            parts = line.split("ï¼š**", 1)
                            key = parts[0].replace("**", "").strip()
                            val = parts[1].strip() if len(parts) > 1 else ""
                            old_fields[key] = val
                except: pass

            # æ™ºèƒ½åˆå¹¶ï¼šé€å­—æ®µåˆ¤å®šæ˜¯å¦ç”¨æ–°å€¼è¦†ç›–
            merged_lines = []
            for key, new_val, confidence in fields:
                if confidence == "low" and key in old_fields:
                    old_val = old_fields[key]
                    # æ—§å€¼ä¸é»˜è®¤æ¨¡æ¿ä¸åŒ â†’ è¯´æ˜ç”¨æˆ·æ‰‹å·¥ä¿®æ”¹è¿‡ï¼Œä¿ç•™æ—§å€¼
                    if old_val and old_val != new_val:
                        merged_lines.append(f"**{key}ï¼š** {old_val}")
                        continue
                merged_lines.append(f"**{key}ï¼š** {new_val}")

            # å¤„ç†å‚¬åŒ–å‰‚æ¢è¡Œï¼ˆç³»ç»Ÿè‡ªåŠ¨æ•è·è¿‘æœŸå‚¬åŒ–å‰‚åœ¨ core_business ä¹‹åï¼‰
            md = "\n".join(merged_lines) + "\n"

            with open(panel_path, "w", encoding="utf-8") as f:
                f.write(md)
                if old_rag:
                    f.write(old_rag)
            print(f"âœ… å‚æ•°é¢æ¿å·²æ™ºèƒ½åˆå¹¶æ›´æ–° (æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')})")
            print(f"   â†’ ä½ä¿¡å¿ƒå­—æ®µå·²ä¿ç•™æ‚¨çš„æ‰‹å·¥ä¿®æ”¹ï¼Œé«˜ä¿¡å¿ƒå­—æ®µå·²åˆ·æ–°")
            
            if self.db_collection is not None:
                try:
                    self.db_collection.insert_one({
                        "code": code, "name": name, "timestamp": datetime.now(),
                        "price": p_now, "pe_ttm": pe_ttm, "pb": pb,
                        "turnover": turnover, "rise_from_bottom": rise_from_bottom,
                        "eps_forecast": eps_forecast
                    })
                    print("â˜ï¸ [MongoDB] æ•°æ®å·²åŒæ­¥è‡³é¶æ ‡åº“ã€‚")
                except Exception: pass
        except Exception as e:
            print(f"âš ï¸ æ ¸å¿ƒå‚æ•°ç»„è£…å—æŸ: {e}")

    def _dl_cninfo(self, code, cat, limit, save_dir, searchkey=None):
        # è·å– orgId ç”¨äºæ„å»ºæ­£ç¡®çš„ stock å‚æ•°ï¼ˆæ ¼å¼: "code,orgId"ï¼‰
        org_id = self._get_cninfo_orgid(code)
        stock_param = f"{code},{org_id}" if org_id else f"{code},"
        # æ ¹æ®è‚¡ç¥¨ä»£ç è‡ªåŠ¨é€‚é…äº¤æ˜“æ‰€
        column = "sse" if str(code).startswith('6') else "szse"
        payload = {"pageNum": 1, "pageSize": 20, "column": column, "tabName": "fulltext", 
                   "stock": stock_param, "isHLtitle": "true"}
        if cat:  # ä¸ä¸ºç©ºæ‰ä¼  category
            payload["category"] = cat
        if searchkey:
            payload["searchkey"] = searchkey
        try:
            res_obj = self._safe_request(self.cninfo_url, method="post", data=payload)
            if not res_obj: return
            res = res_obj.json()
            
            if not res.get('announcements'): return
            count = 0
            # æŠ•èµ„è€…çºªè¦ç±»åˆ«å…³é”®è¯åˆ—è¡¨ï¼ˆåå¤„ç†è¿‡æ»¤ï¼Œé¿å… searchkey è¿‡æ»¤å¯¼è‡´æ— ç»“æœï¼‰
            INVESTOR_KEYWORDS = ['æŠ•èµ„è€…å…³ç³»æ´»åŠ¨è®°å½•', 'æŠ•èµ„è€…è°ƒç ”', 'è°ƒç ”æ¥å¾…', 'é—®å·è°ƒæŸ¥', 'æŠ•èµ„è€…é—®å·']
            is_investor_cat = cat in ('category_rcys_szsh',) or (searchkey and 'æŠ•èµ„è€…' in searchkey)
            for ann in res['announcements']:
                if count >= limit: break
                raw_title = ann['secName'] + "_" + ann['announcementTitle']
                clean_title = re.sub(r'[\\/*?:"<>|]', "", raw_title).replace(" ", "_").replace("\n", "")

                if "è‹±æ–‡" in clean_title or "æ‘˜è¦" in clean_title: continue
                # æŠ•èµ„è€…ç±»åˆ«ï¼šå¦‚æœæ ‡é¢˜ä¸åŒ…å«ä»»ä½•æŠ•èµ„è€…å…³é”®è¯åˆ™è·³è¿‡
                if is_investor_cat:
                    if not any(kw in raw_title for kw in INVESTOR_KEYWORDS):
                        continue

                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼ˆå¢é‡åˆå¹¶ï¼‰ï¼Œè·³è¿‡
                pdf_path = os.path.join(save_dir, f"{clean_title}.pdf")
                if os.path.exists(pdf_path):
                    print(f"  â­ï¸ å·²å­˜åœ¨ï¼Œè·³è¿‡: {clean_title[:35]}...")
                    count += 1
                    continue
                
                print(f"  â¬‡ï¸ æµå¼å†™å…¥ä¸­: {clean_title[:35]}...pdf")
                # å¯ç”¨å†›å·¥çº§ Stream å†™å…¥ï¼Œé˜²å†…å­˜å´©å¡Œ
                pdf_res = self._safe_request(self.cninfo_dl_base + ann['adjunctUrl'], method="get", stream=True)
                if pdf_res:
                    pdf_path = os.path.join(save_dir, f"{clean_title}.pdf")
                    with open(pdf_path, 'wb') as f:
                        for chunk in pdf_res.iter_content(chunk_size=8192):
                            f.write(chunk)
                            
                    if PdfReader and ("å¹´æŠ¥" in raw_title or "è°ƒç ”" in raw_title):
                        try:
                            reader = PdfReader(pdf_path)
                            extracted = []
                            for i in range(min(5, len(reader.pages))):
                                text = reader.pages[i].extract_text()
                                if text:
                                    sentences = re.split(r'[ã€‚ï¼\n]', text)
                                    for s in sentences:
                                        if re.search(r'(äº§èƒ½|æ»¡äº§|å¼€å‘|ç ”å‘|çªç ´|ä¾›ä¸åº”æ±‚|è®¢å•|å¤§å¹…å¢é•¿)', s):
                                            c_s = s.strip()
                                            if len(c_s) > 10 and len(c_s) < 100 and c_s not in extracted:
                                                extracted.append(c_s)
                            if extracted:
                                with open(os.path.join(save_dir, "00_å‚æ•°é¢æ¿_å‘ç»™AI.md"), "a", encoding="utf-8") as mdf:
                                    mdf.write(f"\n\n### ğŸ“„ {clean_title[:30]} - å¢é‡ RAG æçº¯æ•°æ®:\n")
                                    for info in extracted[:5]:
                                        mdf.write(f"- {info}\n")
                        except Exception: pass
                count += 1
                time.sleep(1.0)
        except Exception as e:
            print(f"  [x] ä¸‹è½½çº¿ç¨‹ä¸­æ–­: {e}")

if __name__ == "__main__":
    terminal = OmniTerminal()
    while True:
        print("\n" + "â–ˆ"*65 + "\n ğŸŒŒ Omni-Analyst v7.0 Singularity (å¥‡ç‚¹é™ä¸´ç‰ˆ)\n" + "â–ˆ"*65)
        print(" [1] ğŸ“¡ å¥‡ç‚¹é›·è¾¾ (å¤šç»´æƒ…æŠ¥å…±æŒ¯ â˜…â˜…â˜… + é¾™è™æ¦œçœŸé‡‘åˆºé€)")
        print(" [2] ğŸ“¥ å¥‡ç‚¹æ‰“åŒ… (æ­»äº¡æ¢æ‰‹è‡ªåŠ¨ç†”æ–­ + å®è§‚æµåŠ¨æ€§è‡ªåŠ¨å®šæ ‡)")
        print("     â””â”€ æ”¯æŒæ‰¹é‡è¾“å…¥ï¼å¤šåªè‚¡ç¥¨ç”¨é€—å·/ç©ºæ ¼åˆ†éš”")
        print(" [0] åˆ‡æ–­æ•°æ®è¿çº¿ (é€€å‡º)")
        c = input("\nğŸ‘‰ è¾“å…¥æŒ‡ä»¤æ•°å­—: ").strip()
        
        if c == '1': terminal.module_1_intel_radar()
        elif c == '2':
            raw_input = input("ğŸ¯ è¾“å…¥Aè‚¡ä»£ç /åç§° (å¤šåªç”¨é€—å·æˆ–ç©ºæ ¼åˆ†éš”, å¦‚: 000001,002648 601318): ").strip()
            # è§£ææ‰¹é‡è¾“å…¥ï¼šæ”¯æŒé€—å·ã€ç©ºæ ¼ã€é¡·å·ã€ä¸­æ–‡é€—å·åˆ†éš”
            codes = [s.strip() for s in re.split(r'[,ï¼Œ\s;]+', raw_input) if s.strip()]
            if not codes:
                print("âš ï¸ æœªè¾“å…¥ä»»ä½•è‚¡ç¥¨ä»£ç ")
                continue
            print(f"\nğŸš€ æ‰¹é‡ä»»åŠ¡å¯åŠ¨ï¼Œå…± {len(codes)} åªè‚¡ç¥¨: {codes}")
            for i, code in enumerate(codes, 1):
                print(f"\n{'='*50}")
                print(f"ğŸ“Œ [{i}/{len(codes)}] æ­£åœ¨å¤„ç†: {code}")
                print(f"{'='*50}")
                terminal.module_2_audit_prep(code)
            print(f"\nğŸ‰ æ‰¹é‡ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼å…±å¤„ç† {len(codes)} åªè‚¡ç¥¨")
        elif c == '0': break